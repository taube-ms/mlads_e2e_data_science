{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Titanic Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the classes and functions we need\n",
    "from mlads_ds.data_loader import DataLoader\n",
    "from mlads_ds.data_preprocessor import DataPreprocessor\n",
    "from mlads_ds.feature_engineer import FeatureEngineer\n",
    "from mlads_ds.model_trainer import ModelTrainer\n",
    "from mlads_ds.model_evaluator import ModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    loader = DataLoader('../titanic.csv')\n",
    "    data = loader.load_data()\n",
    "\n",
    "    # Preprocess data\n",
    "    preprocessor = DataPreprocessor(data)\n",
    "    preprocessed_data = preprocessor.preprocess()\n",
    "\n",
    "    # Feature engineering\n",
    "    engineer = FeatureEngineer(preprocessed_data)\n",
    "    engineered_data = engineer.engineer_features()\n",
    "\n",
    "    # Splitting features and target\n",
    "    features = engineered_data.drop('Survived', axis=1)\n",
    "    target = engineered_data['Survived']\n",
    "\n",
    "    # Model training\n",
    "    trainer = ModelTrainer(features, target)\n",
    "    trained_model = trainer.train_and_tune()\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the main function\n",
    "accuracy = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic_regression': {'best_params': {'model__C': 0.1},\n",
       "  'best_score': 0.783669851275485,\n",
       "  'test_score': 0.776536312849162,\n",
       "  'confusion_matrix': array([[87, 18],\n",
       "         [22, 52]], dtype=int64),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.80      0.83      0.81       105\\n           1       0.74      0.70      0.72        74\\n\\n    accuracy                           0.78       179\\n   macro avg       0.77      0.77      0.77       179\\nweighted avg       0.78      0.78      0.78       179\\n'},\n",
       " 'random_forest': {'best_params': {'model__n_estimators': 100},\n",
       "  'best_score': 0.7753373387176203,\n",
       "  'test_score': 0.7374301675977654,\n",
       "  'confusion_matrix': array([[82, 23],\n",
       "         [24, 50]], dtype=int64),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.77      0.78      0.78       105\\n           1       0.68      0.68      0.68        74\\n\\n    accuracy                           0.74       179\\n   macro avg       0.73      0.73      0.73       179\\nweighted avg       0.74      0.74      0.74       179\\n'},\n",
       " 'svm': {'best_params': {'model__C': 1, 'model__gamma': 'scale'},\n",
       "  'best_score': 0.7977248104008667,\n",
       "  'test_score': 0.7821229050279329,\n",
       "  'confusion_matrix': array([[87, 18],\n",
       "         [21, 53]], dtype=int64),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.81      0.83      0.82       105\\n           1       0.75      0.72      0.73        74\\n\\n    accuracy                           0.78       179\\n   macro avg       0.78      0.77      0.77       179\\nweighted avg       0.78      0.78      0.78       179\\n'},\n",
       " 'knn': {'best_params': {'model__metric': 'manhattan',\n",
       "   'model__n_neighbors': 19,\n",
       "   'model__weights': 'distance'},\n",
       "  'best_score': 0.787914901999409,\n",
       "  'test_score': 0.7486033519553073,\n",
       "  'confusion_matrix': array([[85, 20],\n",
       "         [25, 49]], dtype=int64),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.77      0.81      0.79       105\\n           1       0.71      0.66      0.69        74\\n\\n    accuracy                           0.75       179\\n   macro avg       0.74      0.74      0.74       179\\nweighted avg       0.75      0.75      0.75       179\\n'},\n",
       " 'decision_tree': {'best_params': {'model__max_depth': 10,\n",
       "   'model__min_samples_split': 10},\n",
       "  'best_score': 0.776696542893726,\n",
       "  'test_score': 0.7318435754189944,\n",
       "  'confusion_matrix': array([[91, 14],\n",
       "         [34, 40]], dtype=int64),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.73      0.87      0.79       105\\n           1       0.74      0.54      0.62        74\\n\\n    accuracy                           0.73       179\\n   macro avg       0.73      0.70      0.71       179\\nweighted avg       0.73      0.73      0.72       179\\n'},\n",
       " 'gradient_boosting': {'best_params': {'model__learning_rate': 0.01,\n",
       "   'model__max_depth': 5,\n",
       "   'model__n_estimators': 300},\n",
       "  'best_score': 0.8160248202501723,\n",
       "  'test_score': 0.8044692737430168,\n",
       "  'confusion_matrix': array([[95, 10],\n",
       "         [25, 49]], dtype=int64),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.79      0.90      0.84       105\\n           1       0.83      0.66      0.74        74\\n\\n    accuracy                           0.80       179\\n   macro avg       0.81      0.78      0.79       179\\nweighted avg       0.81      0.80      0.80       179\\n'},\n",
       " 'adaboost': {'best_params': {'model__learning_rate': 0.01,\n",
       "   'model__n_estimators': 50},\n",
       "  'best_score': 0.7878755047769133,\n",
       "  'test_score': 0.7821229050279329,\n",
       "  'confusion_matrix': array([[88, 17],\n",
       "         [22, 52]], dtype=int64),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.80      0.84      0.82       105\\n           1       0.75      0.70      0.73        74\\n\\n    accuracy                           0.78       179\\n   macro avg       0.78      0.77      0.77       179\\nweighted avg       0.78      0.78      0.78       179\\n'},\n",
       " 'xgboost': {'best_params': {'model__learning_rate': 0.01,\n",
       "   'model__max_depth': 5,\n",
       "   'model__n_estimators': 200},\n",
       "  'best_score': 0.8033684625233921,\n",
       "  'test_score': 0.776536312849162,\n",
       "  'confusion_matrix': array([[94, 11],\n",
       "         [29, 45]], dtype=int64),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.76      0.90      0.82       105\\n           1       0.80      0.61      0.69        74\\n\\n    accuracy                           0.78       179\\n   macro avg       0.78      0.75      0.76       179\\nweighted avg       0.78      0.78      0.77       179\\n'},\n",
       " 'lightgbm': {'best_params': {'model__learning_rate': 0.1,\n",
       "   'model__n_estimators': 100,\n",
       "   'model__num_leaves': 31},\n",
       "  'best_score': 0.7991726583275879,\n",
       "  'test_score': 0.7877094972067039,\n",
       "  'confusion_matrix': array([[88, 17],\n",
       "         [21, 53]], dtype=int64),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.81      0.84      0.82       105\\n           1       0.76      0.72      0.74        74\\n\\n    accuracy                           0.79       179\\n   macro avg       0.78      0.78      0.78       179\\nweighted avg       0.79      0.79      0.79       179\\n'},\n",
       " 'naive_bayes': {'best_params': {},\n",
       "  'best_score': 0.7836501526642371,\n",
       "  'test_score': 0.770949720670391,\n",
       "  'confusion_matrix': array([[86, 19],\n",
       "         [22, 52]], dtype=int64),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.80      0.82      0.81       105\\n           1       0.73      0.70      0.72        74\\n\\n    accuracy                           0.77       179\\n   macro avg       0.76      0.76      0.76       179\\nweighted avg       0.77      0.77      0.77       179\\n'},\n",
       " 'linear_svc': {'best_params': {'model__C': 0.1},\n",
       "  'best_score': 0.783669851275485,\n",
       "  'test_score': 0.7821229050279329,\n",
       "  'confusion_matrix': array([[88, 17],\n",
       "         [22, 52]], dtype=int64),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.80      0.84      0.82       105\\n           1       0.75      0.70      0.73        74\\n\\n    accuracy                           0.78       179\\n   macro avg       0.78      0.77      0.77       179\\nweighted avg       0.78      0.78      0.78       179\\n'},\n",
       " 'extra_trees': {'best_params': {'model__max_depth': 10,\n",
       "   'model__n_estimators': 100},\n",
       "  'best_score': 0.796385304836009,\n",
       "  'test_score': 0.7486033519553073,\n",
       "  'confusion_matrix': array([[84, 21],\n",
       "         [24, 50]], dtype=int64),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.78      0.80      0.79       105\\n           1       0.70      0.68      0.69        74\\n\\n    accuracy                           0.75       179\\n   macro avg       0.74      0.74      0.74       179\\nweighted avg       0.75      0.75      0.75       179\\n'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783669851275485\n",
      "0.7753373387176203\n",
      "0.7977248104008667\n",
      "0.787914901999409\n",
      "0.776696542893726\n",
      "0.8160248202501723\n",
      "0.7878755047769133\n",
      "0.8033684625233921\n",
      "0.7991726583275879\n",
      "0.7836501526642371\n",
      "0.783669851275485\n",
      "0.796385304836009\n"
     ]
    }
   ],
   "source": [
    "for result in accuracy:\n",
    "    print(accuracy[result]['best_score'])\n",
    "\n",
    "# find the model with the highest accuracy\n",
    "max_accuracy = 0\n",
    "best_model = None\n",
    "for result in accuracy:\n",
    "    if accuracy[result]['best_score'] > max_accuracy:\n",
    "        max_accuracy = accuracy[result]['best_score']\n",
    "        best_model = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gradient_boosting', 0.8160248202501723)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model, max_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
