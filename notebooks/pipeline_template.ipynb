{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science pipeline for titnaic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT:\n",
    "\n",
    "The data science pipeline for the Titanic dataset, structured into different classes, yielded the following results:\n",
    "\n",
    "Data Loading: The dataset was successfully loaded from the provided file path.\n",
    "\n",
    "Data Preprocessing: Missing values were handled (median for 'Age', mode for 'Embarked', and dropping the 'Cabin' column). Categorical variables ('Sex' and 'Embarked') were encoded.\n",
    "\n",
    "Feature Selection: Relevant features were selected, including 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', and encoded 'Sex' and 'Embarked' columns.\n",
    "\n",
    "Model Training: A Random Forest Classifier was trained with the selected features. The dataset was split into training and testing sets, with 80% of the data used for training.\n",
    "\n",
    "Model Evaluation: The trained model was evaluated on the test set. The model achieved an accuracy of approximately 82.12%. The classification report provides further details:\n",
    "\n",
    "Precision for non-survivors (0) was 85%, and for survivors (1) was 78%.\n",
    "Recall for non-survivors was 86%, and for survivors was 75%.\n",
    "The F1-score, which balances precision and recall, was 86% for non-survivors and 76% for survivors.\n",
    "The pipeline demonstrates a systematic approach to handling a data science task, with each step encapsulated in a separate class, enhancing modularity and clarity. The model's performance indicates a good level of predictive ability, especially in distinguishing between survivors and non-survivors on the Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8212290502793296,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.85      0.86      0.86       110\\n           1       0.78      0.75      0.76        69\\n\\n    accuracy                           0.82       179\\n   macro avg       0.81      0.81      0.81       179\\nweighted avg       0.82      0.82      0.82       179\\n')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a generic data science pipeline for the Titanic dataset\n",
    "# Each step in the pipeline will be a separate class\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Load the dataset.\"\"\"\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def load_data(self):\n",
    "        return pd.read_csv(self.file_path)\n",
    "\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"Preprocess the data: handle missing values, encode categorical variables, etc.\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def preprocess(self):\n",
    "        # Filling missing values\n",
    "        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)\n",
    "        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)\n",
    "        self.data.drop('Cabin', axis=1, inplace=True)  # Dropping the Cabin column due to high missing values\n",
    "\n",
    "        # Encoding categorical variables\n",
    "        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "        return self.data\n",
    "\n",
    "\n",
    "class FeatureSelector:\n",
    "    \"\"\"Select features for the model.\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def select_features(self):\n",
    "        features = self.data[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S']]\n",
    "        return features\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Train the machine learning model.\"\"\"\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def train_model(self):\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "        # Splitting the dataset into the Training set and Test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.features, self.labels, test_size=0.2, random_state=0)\n",
    "\n",
    "        # Fitting Random Forest Classification to the Training set\n",
    "        classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        return classifier, X_test, y_test\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"Evaluate the trained model.\"\"\"\n",
    "    def __init__(self, model, X_test, y_test):\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def evaluate(self):\n",
    "        from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "        # Predicting the Test set results\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "\n",
    "        # Creating the evaluation report\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        report = classification_report(self.y_test, y_pred)\n",
    "\n",
    "        return accuracy, report\n",
    "\n",
    "\n",
    "# Using the classes to create a pipeline\n",
    "file_path = '../titanic.csv'\n",
    "\n",
    "# Load data\n",
    "data_loader = DataLoader(file_path)\n",
    "data = data_loader.load_data()\n",
    "\n",
    "# Preprocess data\n",
    "preprocessor = DataPreprocessor(data)\n",
    "processed_data = preprocessor.preprocess()\n",
    "\n",
    "# Select features and labels\n",
    "selector = FeatureSelector(processed_data)\n",
    "features = selector.select_features()\n",
    "labels = processed_data['Survived']\n",
    "\n",
    "# Train model\n",
    "trainer = ModelTrainer(features, labels)\n",
    "model, X_test, y_test = trainer.train_model()\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = ModelEvaluator(model, X_test, y_test)\n",
    "accuracy, report = evaluator.evaluate()\n",
    "\n",
    "accuracy, report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
