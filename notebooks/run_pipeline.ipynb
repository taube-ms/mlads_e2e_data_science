{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "from mlads_ds.data_loader import DataLoader\n",
    "from mlads_ds.data_preprocessor import DataPreprocessor\n",
    "from mlads_ds.feature_selector import FeatureSelector\n",
    "from mlads_ds.model_trainer import ModelTrainer\n",
    "from mlads_ds.model_evaluator import ModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the classes to create a pipeline\n",
    "file_path = '../titanic.csv'\n",
    "\n",
    "data_loader = DataLoader(file_path)\n",
    "data = data_loader.load_data()\n",
    "preprocessor = DataPreprocessor(data)\n",
    "processed_data = preprocessor.preprocess()\n",
    "selector = FeatureSelector(processed_data)\n",
    "features = selector.select_features()\n",
    "labels = processed_data['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "trainer = ModelTrainer(features, labels)\n",
    "best_models, evaluation_results = trainer.train_and_evaluate_models()\n",
    "\n",
    "# Outputting the results\n",
    "best_models, evaluation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advance run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the experiment\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "models = {\n",
    "            'RandomForest': RandomForestClassifier(),\n",
    "            'SVM': SVC(),\n",
    "            'LogisticRegression': LogisticRegression(),\n",
    "            'NaiveBayes': GaussianNB(),\n",
    "            'DecisionTree': DecisionTreeClassifier(),\n",
    "            'KNeighbors': KNeighborsClassifier(),\n",
    "            'AdaBoost': AdaBoostClassifier(),\n",
    "            'GradientBoosting': GradientBoostingClassifier(),\n",
    "            'RidgeClassifier': RidgeClassifier(),\n",
    "            'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "            'LightGBM': LGBMClassifier()\n",
    "        }\n",
    "hyperparameters = {\n",
    "            'RandomForest': {'n_estimators': [50, 100], 'max_depth': [10, 20]},\n",
    "            'SVM': {'C': [1, 10], 'gamma': [0.1, 0.01]},\n",
    "            'LogisticRegression': {'C': [1, 10]},\n",
    "            'NaiveBayes': {},\n",
    "            'DecisionTree': {'max_depth': [5, 10]},\n",
    "            'KNeighbors': {'n_neighbors': [3, 5]},\n",
    "            'AdaBoost': {'n_estimators': [50, 100]},\n",
    "            'GradientBoosting': {'n_estimators': [50, 100], 'learning_rate': [0.1, 0.01]},\n",
    "            'RidgeClassifier': {'alpha': [0.1, 1]},\n",
    "            'XGBoost': {'n_estimators': [50, 100], 'learning_rate': [0.1, 0.01]},\n",
    "            'LightGBM': {'n_estimators': [50, 100], 'learning_rate': [0.1, 0.01]}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Train and evaluate models\n",
    "trainer = ModelTrainer(features=features, labels=labels, models=models, hyperparameters=hyperparameters)\n",
    "best_models, evaluation_results = trainer.train_and_evaluate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForest': {'Best Parameters': {'max_depth': 10, 'n_estimators': 50},\n",
       "  'Accuracy': 0.8324022346368715,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.83      0.91      0.87       110\\n           1       0.83      0.71      0.77        69\\n\\n    accuracy                           0.83       179\\n   macro avg       0.83      0.81      0.82       179\\nweighted avg       0.83      0.83      0.83       179\\n'},\n",
       " 'SVM': {'Best Parameters': {'C': 10, 'gamma': 0.01},\n",
       "  'Accuracy': 0.7597765363128491,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.79      0.84      0.81       110\\n           1       0.71      0.64      0.67        69\\n\\n    accuracy                           0.76       179\\n   macro avg       0.75      0.74      0.74       179\\nweighted avg       0.76      0.76      0.76       179\\n'},\n",
       " 'LogisticRegression': {'Best Parameters': {'C': 10},\n",
       "  'Accuracy': 0.7988826815642458,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.82      0.85      0.84       110\\n           1       0.75      0.71      0.73        69\\n\\n    accuracy                           0.80       179\\n   macro avg       0.79      0.78      0.79       179\\nweighted avg       0.80      0.80      0.80       179\\n'},\n",
       " 'NaiveBayes': {'Best Parameters': {},\n",
       "  'Accuracy': 0.7932960893854749,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.84      0.82      0.83       110\\n           1       0.72      0.75      0.74        69\\n\\n    accuracy                           0.79       179\\n   macro avg       0.78      0.79      0.78       179\\nweighted avg       0.80      0.79      0.79       179\\n'},\n",
       " 'DecisionTree': {'Best Parameters': {'max_depth': 5},\n",
       "  'Accuracy': 0.8156424581005587,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.82      0.90      0.86       110\\n           1       0.81      0.68      0.74        69\\n\\n    accuracy                           0.82       179\\n   macro avg       0.81      0.79      0.80       179\\nweighted avg       0.82      0.82      0.81       179\\n'},\n",
       " 'KNeighbors': {'Best Parameters': {'n_neighbors': 5},\n",
       "  'Accuracy': 0.7486033519553073,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.76      0.85      0.81       110\\n           1       0.71      0.58      0.64        69\\n\\n    accuracy                           0.75       179\\n   macro avg       0.74      0.72      0.72       179\\nweighted avg       0.74      0.75      0.74       179\\n'},\n",
       " 'AdaBoost': {'Best Parameters': {'n_estimators': 50},\n",
       "  'Accuracy': 0.8156424581005587,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.84      0.86      0.85       110\\n           1       0.77      0.74      0.76        69\\n\\n    accuracy                           0.82       179\\n   macro avg       0.81      0.80      0.80       179\\nweighted avg       0.81      0.82      0.81       179\\n'},\n",
       " 'GradientBoosting': {'Best Parameters': {'learning_rate': 0.1,\n",
       "   'n_estimators': 100},\n",
       "  'Accuracy': 0.8491620111731844,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.83      0.95      0.89       110\\n           1       0.90      0.68      0.78        69\\n\\n    accuracy                           0.85       179\\n   macro avg       0.87      0.82      0.83       179\\nweighted avg       0.86      0.85      0.84       179\\n'},\n",
       " 'RidgeClassifier': {'Best Parameters': {'alpha': 0.1},\n",
       "  'Accuracy': 0.7932960893854749,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.82      0.85      0.83       110\\n           1       0.74      0.71      0.73        69\\n\\n    accuracy                           0.79       179\\n   macro avg       0.78      0.78      0.78       179\\nweighted avg       0.79      0.79      0.79       179\\n'},\n",
       " 'XGBoost': {'Best Parameters': {'learning_rate': 0.01, 'n_estimators': 100},\n",
       "  'Accuracy': 0.8435754189944135,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.82      0.95      0.88       110\\n           1       0.90      0.67      0.77        69\\n\\n    accuracy                           0.84       179\\n   macro avg       0.86      0.81      0.82       179\\nweighted avg       0.85      0.84      0.84       179\\n'},\n",
       " 'LightGBM': {'Best Parameters': {'learning_rate': 0.1, 'n_estimators': 50},\n",
       "  'Accuracy': 0.8435754189944135,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.83      0.95      0.88       110\\n           1       0.89      0.68      0.77        69\\n\\n    accuracy                           0.84       179\\n   macro avg       0.86      0.81      0.83       179\\nweighted avg       0.85      0.84      0.84       179\\n'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GradientBoosting': {'Accuracy': 0.8491620111731844,\n",
       "  'Best Parameters': {'learning_rate': 0.1, 'n_estimators': 100}},\n",
       " 'XGBoost': {'Accuracy': 0.8435754189944135,\n",
       "  'Best Parameters': {'learning_rate': 0.01, 'n_estimators': 100}},\n",
       " 'LightGBM': {'Accuracy': 0.8435754189944135,\n",
       "  'Best Parameters': {'learning_rate': 0.1, 'n_estimators': 50}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the top 3 models based on their accuracy from the evaluation results\n",
    "\n",
    "# Sorting the models based on accuracy\n",
    "sorted_models = sorted(evaluation_results.items(), key=lambda x: x[1]['Accuracy'], reverse=True)\n",
    "\n",
    "# Selecting the top 3 models\n",
    "top_3_models = sorted_models[:3]\n",
    "\n",
    "top_3_models_info = {model_name: {'Accuracy': details['Accuracy'], 'Best Parameters': details['Best Parameters']}\n",
    "                     for model_name, details in top_3_models}\n",
    "\n",
    "top_3_models_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
